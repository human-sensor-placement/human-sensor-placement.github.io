[
  {
    "objectID": "authors.html",
    "href": "authors.html",
    "title": "Authors",
    "section": "",
    "text": "Sein is investigating human spatial cognition using mobile EEG at the Berlin Mobile Brain-Body Imaging Lab & Doellerlab. She is a dedicated Open Science enthusiast!"
  },
  {
    "objectID": "authors.html#sein-jeung",
    "href": "authors.html#sein-jeung",
    "title": "Authors",
    "section": "",
    "text": "Sein is investigating human spatial cognition using mobile EEG at the Berlin Mobile Brain-Body Imaging Lab & Doellerlab. She is a dedicated Open Science enthusiast!"
  },
  {
    "objectID": "authors.html#julius-welzel",
    "href": "authors.html#julius-welzel",
    "title": "Authors",
    "section": "Julius Welzel",
    "text": "Julius Welzel\nJulius has completed his masters in 2019 in Cognitive Neuropsychology in Oldenburg, Germany and is still pursuing his PhD in Kiel, Germany where he started building a Open Science EEG lab based in the deparment of Neurology. He has a daughter which you can meet at conferences or in one of his many Zoom calls."
  },
  {
    "objectID": "authors.html#seyed-yahya-shirazi",
    "href": "authors.html#seyed-yahya-shirazi",
    "title": "Authors",
    "section": "Seyed (Yahya) Shirazi",
    "text": "Seyed (Yahya) Shirazi\nYahya is an Assistant Project Scientist at the Swartz center for Computational Neuroscience working hard to make the MOBI world a better place."
  },
  {
    "objectID": "authors.html#lara-godbersen",
    "href": "authors.html#lara-godbersen",
    "title": "Authors",
    "section": "Lara Godbersen",
    "text": "Lara Godbersen\nLara is a Master student at the Kiel University. She is interested in the field of cognitive neuroscience and just finished her master thesis with advanced EEG processing."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture",
    "section": "",
    "text": "Note\n\n\n\nThis website presents a unified framework for sensor placement in human motion capture and wearable applications. For the complete research paper, please visit our preprint on ArXiv.\n\n\n\n\nThe proliferation of wearable sensors and monitoring technologies has created an urgent need for standardized sensor placement protocols. While existing standards like SENIAM address specific applications, there is no comprehensive framework that spans different sensing modalities and applications. We present a unified sensor placement standard that ensures reproducibility and transferability of human movement data across different recording systems and research domains.\n\n\n\n\n\nA reference frame consists of an origin point and a set of axes that define directions in space. In human movement analysis, we encounter multiple reference frames:\n\nGlobal laboratory frame: The fixed reference frame of the measurement space\nAnatomical frames: Tied to specific body segments\nSensor-specific frames: Related to individual sensor positioning\n\nA coordinate system is fully described by: 1. The origin relative to which coordinates are expressed 2. The interpretation of the three axes 3. The units in which measurements are expressed\n\n\n\nReference frames can have a hierarchical structure, where one frame is nested within another. For example: - Torso position within the room frame - Arm position relative to the torso - Hand position relative to the arm\nThe global reference frame sits at the top of this hierarchy, associated with the space through which the entire body moves.\n\n\n\n\n\n\nWe define precise anatomical coordinate systems for each body segment using palpable landmarks. These definitions ensure consistent interpretation and implementation across different applications.\n\n\n\n\n\n\nNote\n\n\n\nThe complete anatomical landmark table with detailed coordinate systems for all body segments is available here.\n\n\n\n\n\nOur unified placement scheme follows these core principles:\n\nSensor placement must be reproducible by a human with defined precision\nPlacement coordinates relate to anatomical landmarks of the relevant body part\nLandmarks define the origin, direction, and limits of axes\nSensor locations are reported as ratios of the axis limits\nPlacement precision depends on landmarks, axes, and measurement method\n\n\n\n\nWe define three levels of placement precision:\n\nLevel 1: ~10% precision, such as Visual Inspection\n\nPlacement defined by visual inspection of body parts and landmarks\nLimited by human eye resolution and alignment ability\n\nLevel 2: ~5% precision, such as Tape Measure\n\nPlacement defined by measuring distances between landmarks\nLimited by tape measure resolution and alignment ability\n\nLevel 3: ~1% precision, such as 3D Scanning\n\nPlacement defined by 3D scanning body parts\nLimited by scanner resolution and alignment ability\n\n\n\n\n\nSensor placement should be documented using a standardized format that includes:\n\nBody part name\nAxis name and direction\nAxis limits\nSensor location (as ratio of axis limits)\nPlacement precision level\n\nThis framework does not prescribe specific annotation formats; different standards and specification can use the principles to develop their own. However, this framework is designed to be compatible with existing data sharing standards such as Brain Imaging Data Structure (BIDS) and Hierarchical Event Descriptors (HED). Specifically, using this framework would provide precise details for the sensor placement as described in Motion-BIDS.\nAn exemplar annotation following the general HED instructions can be represented as:\n(Body-part, (X-position/#, Y-position/#, Z-position/#), Precision)\n(note that the exact HED tags are under development under HED-SLAM)\nThis standardization framework represents a significant step toward improving data quality, reproducibility, and interoperability in human movement analysis, from clinical biomechanics to continuous health monitoring.\n\n\n\n\nContributions: We welcome contributions to this framework from the research community. Please submit your suggestions and feedback via the GitHub repository Issues section.\nThere are specific areas where we seek contributions:\n\nStandard vocabulary and communication formats through BIDS, HED, and other specifications\nValidation studies for inter-operator reliability assessment\nMappings between this framework and existing standards (such as SENIAM)\nSoftware tools for coordinate calculation and placement visualization"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture",
    "section": "",
    "text": "The proliferation of wearable sensors and monitoring technologies has created an urgent need for standardized sensor placement protocols. While existing standards like SENIAM address specific applications, there is no comprehensive framework that spans different sensing modalities and applications. We present a unified sensor placement standard that ensures reproducibility and transferability of human movement data across different recording systems and research domains."
  },
  {
    "objectID": "index.html#fundamentals",
    "href": "index.html#fundamentals",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture",
    "section": "",
    "text": "A reference frame consists of an origin point and a set of axes that define directions in space. In human movement analysis, we encounter multiple reference frames:\n\nGlobal laboratory frame: The fixed reference frame of the measurement space\nAnatomical frames: Tied to specific body segments\nSensor-specific frames: Related to individual sensor positioning\n\nA coordinate system is fully described by: 1. The origin relative to which coordinates are expressed 2. The interpretation of the three axes 3. The units in which measurements are expressed\n\n\n\nReference frames can have a hierarchical structure, where one frame is nested within another. For example: - Torso position within the room frame - Arm position relative to the torso - Hand position relative to the arm\nThe global reference frame sits at the top of this hierarchy, associated with the space through which the entire body moves."
  },
  {
    "objectID": "index.html#unified-placement-framework",
    "href": "index.html#unified-placement-framework",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture",
    "section": "",
    "text": "We define precise anatomical coordinate systems for each body segment using palpable landmarks. These definitions ensure consistent interpretation and implementation across different applications.\n\n\n\n\n\n\nNote\n\n\n\nThe complete anatomical landmark table with detailed coordinate systems for all body segments is available here.\n\n\n\n\n\nOur unified placement scheme follows these core principles:\n\nSensor placement must be reproducible by a human with defined precision\nPlacement coordinates relate to anatomical landmarks of the relevant body part\nLandmarks define the origin, direction, and limits of axes\nSensor locations are reported as ratios of the axis limits\nPlacement precision depends on landmarks, axes, and measurement method\n\n\n\n\nWe define three levels of placement precision:\n\nLevel 1: ~10% precision, such as Visual Inspection\n\nPlacement defined by visual inspection of body parts and landmarks\nLimited by human eye resolution and alignment ability\n\nLevel 2: ~5% precision, such as Tape Measure\n\nPlacement defined by measuring distances between landmarks\nLimited by tape measure resolution and alignment ability\n\nLevel 3: ~1% precision, such as 3D Scanning\n\nPlacement defined by 3D scanning body parts\nLimited by scanner resolution and alignment ability\n\n\n\n\n\nSensor placement should be documented using a standardized format that includes:\n\nBody part name\nAxis name and direction\nAxis limits\nSensor location (as ratio of axis limits)\nPlacement precision level\n\nThis framework does not prescribe specific annotation formats; different standards and specification can use the principles to develop their own. However, this framework is designed to be compatible with existing data sharing standards such as Brain Imaging Data Structure (BIDS) and Hierarchical Event Descriptors (HED). Specifically, using this framework would provide precise details for the sensor placement as described in Motion-BIDS.\nAn exemplar annotation following the general HED instructions can be represented as:\n(Body-part, (X-position/#, Y-position/#, Z-position/#), Precision)\n(note that the exact HED tags are under development under HED-SLAM)\nThis standardization framework represents a significant step toward improving data quality, reproducibility, and interoperability in human movement analysis, from clinical biomechanics to continuous health monitoring."
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture",
    "section": "",
    "text": "Contributions: We welcome contributions to this framework from the research community. Please submit your suggestions and feedback via the GitHub repository Issues section.\nThere are specific areas where we seek contributions:\n\nStandard vocabulary and communication formats through BIDS, HED, and other specifications\nValidation studies for inter-operator reliability assessment\nMappings between this framework and existing standards (such as SENIAM)\nSoftware tools for coordinate calculation and placement visualization"
  },
  {
    "objectID": "paper.html",
    "href": "paper.html",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "Published on arXiv: 2412.21159\nBy: Seyed Yahya Shirazi1*, Julius Welzel2*, Sein Jeung3,4*, and Lara Godbersen2\n1. Swartz Center for Computational Neuroscience, Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA\n2. Kiel University, Kiel, Germany\n3. Technical University of Berlin, Berlin, Germany.\n4. Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany.\n* Equal contribution.\n\n\nThe proliferation of wearable sensors and monitoring technologies has created an urgent need for standardized sensor placement protocols. While existing standards like SENIAM address specific applications, no comprehensive framework spans different sensing modalities and applications. We present a unified sensor placement standard that ensures the reproducibility and transferability of human movement and physiological data across various systems and research domains. Our framework provides precise anatomical landmarks, coordinate systems, and placement protocols with defined precision levels, compatible with existing data-sharing standards such as the Brain Imaging Data Structure (BIDS) and Heirechciacal Event Descriptors (HED). This framework aims to enhance data quality, reproducibility, and interoperability in applications ranging from lab-based clinical biomechanics to continuous health monitoring in everyday life.\n\n\n\nThe measurement of human movement and physiological signals is fundamental to fields ranging from biomechanics and clinical rehabilitation to continuous health monitoring and virtual reality. Technological advancements in motion capture systems, inertial sensors, and wearable devices have expanded analysis beyond traditional laboratory settings. Standardization of sensor placement practices is essential to improve data quality, reproducibility, and interoperability across these diverse applications.\nThe impact of sensor placement variation on data quality is well-documented. In biomechanics research, studies have shown that even small changes in sensor position can significantly affect measurement outcomes. In electromyography (EMG), electrode placement variations of just 2-3 cm can lead to signal amplitude changes of up to 50% and altered muscle activation patterns [1]. Similar effects have been observed with inertial measurement units (IMUs), where placement variations can substantially impact acceleration and angular velocity measurements during dynamic movements [2]. The same applies to Optical Motion Capture, where deviations from the predefined marker positions affect gait detection accuracy [3].\nPrecise sensor placement is critical beyond movement analysis. In electrocardiography (ECG), electrode positioning directly affects waveform morphology and diagnostic accuracy, with small deviations potentially leading to misinterpretation of cardiac conditions [4-6]. Continuous glucose monitoring systems require consistent sensor placement to maintain measurement accuracy and reduce variability. Temperature monitoring, particularly for early fever detection or athletic performance, depends heavily on sensor location due to significant variations in skin temperature across different body regions. Emerging technologies like sweat-based biochemical sensors also necessitate standardized placement to account for regional variations in sweat gland density and composition.\nCurrent standards for sensor placement, such as SENIAM for EMG [7] or the Mason-Likar configuration for ECG [8,9], while valuable, are limited and not comprehensive for modern sensing modalities. Moreover, these standards are often not sufficiently implemented in practice [10,11], failing to incorporate a wider user base with varying levels of expertise in anatomy, biomechanics, and biosensors.\nThe emergence of consumer wearables and virtual reality applications has further highlighted the limitations of current standards. These technologies often combine multiple sensing modalities—motion, heart rate, temperature, and other physiological parameters—requiring consistent sensor placement for reliable long-term monitoring and accurate data collection. The growing integration of these technologies demands a unified approach to sensor placement that accommodates different measurement contexts while maintaining precision and reproducibility.\nThe need for a comprehensive sensor placement standard is increasingly pressing with the rise of large-scale data-sharing initiatives and the use of machine-learning techniques in health monitoring and movement analysis. These applications require consistent and well-documented data collection protocols for meaningful comparisons and reliable results. Current data-sharing standards like BIDS [12] and HED [13] provide robust frameworks for data organization but lack specific guidelines for sensor placement across the full range of human monitoring applications.\nWe present a unified sensor placement framework addressing these challenges through a comprehensive system of anatomical landmarks, coordinate systems, and placement protocols. Our standard defines anatomical reference points and coordinate systems for body segments [14], establishes a hierarchical system of reference frames for different measurement contexts, and provides quantifiable levels of placement precision with associated uncertainty estimates. The framework is technology- and specification-agnostic, accommodating various sensing modalities while maintaining compatibility with existing data-sharing standards. This framework will also allow existing records to be annotated with the proposed framework.\nThe following sections detail our proposed standard, beginning with fundamental definitions and proceeding to specific placement protocols for different body segments and sensing modalities. We provide guidance on precision levels and documentation requirements, concluding with recommendations for implementation and validation. This framework represents a significant step toward standardizing sensor placement across the broader field of human biosensing, from traditional biomechanics applications to emerging technologies in continuous health monitoring and virtual reality.\n\n\n\n\n\nThe foundation of our standardization framework rests on precise definitions of anatomical landmarks and spatial references. These definitions ensure consistent interpretation and implementation across different applications and laboratories.\nA reference frame consists of an origin point and a set of axes that define directions in space. In human movement analysis, we encounter multiple reference frames: the global laboratory frame, anatomical frames tied to body segments, and sensor- or system-specific frames. The relationships between these frames must be clearly defined to ensure meaningful data interpretation.\nThe anatomical reference frame for each body segment is defined using palpable landmarks that can be reliably identified (see Anatomical Landmark System). These landmarks are used to define the coordinate system of a body segment to provide reference points for sensor placement. Our framework defines each coordinate system through:\n1. An origin point based on specific anatomical landmarks\n2. Primary axes aligned with functional anatomical directions\n3. Clear definitions of positive directions and measurement conventions\n\n\n\nOur framework defines sensor placement locations using local anatomical coordinate systems. These local systems are part of a larger kinematic chain. This approach aligns with practices in biomechanics and robotics, where transformations between local and global coordinate systems are computed through forward kinematics. Although our standard focuses on precise local definitions, users can derive global coordinates through standard transformation techniques. This separation of local definitions from global transformations ensures both precision in sensor placement and flexibility in data analysis.\n\n\n\nOur framework establishes a comprehensive set of anatomical landmarks chosen for their reliability, accessibility across different body types, relevance to common sensor placement needs, and minimal displacement during movement. Each landmark is defined using standardized anatomical terminology and palpation methods to ensure reproducibility. The complete set of landmarks and their definitions is provided in the anatomical landmark table (link), forming the backbone of our standardization system.\n\n\n\nSensor placement precision is quantified through a three-tier system based on the measurement method used:\nLevel 1: ±10% of reference distance, example: visual inspection or eyeballing\nLevel 2: ±5% of reference distance, example: manual measurement using tape\nLevel 3:±1% of reference distance, example: 3D scanning or motion capture-assisted placement\nThese precision levels must be reported with all sensor placement descriptions to ensure appropriate interpretation of the collected data.\n\n\n\n\nThe core of our framework is a unified placement scheme that defines sensor locations relative to anatomical landmarks using standardized coordinate systems. Each sensor location is specified in three steps:\n\nIdentify the relevant body segment and its anatomical coordinate system\n\nDetermine the location using normalized coordinates within that local body segment coordinate system (0-100% along each axis)\n\nDetermine the precision level of the sensor location (choose one precision level, see Precision Specifications above).\n\nThis standardized approach ensures reproducibility across different operators and laboratories, scalability to different body sizes and proportions, and clear documentation in research publications. The scheme provides a foundation for consistent sensor placement while maintaining the flexibility needed for diverse applications in human movement analysis.\n\n\n\nThe practical implementation of our framework relies on precisely defined anatomical landmarks and their relationships. While the complete system covers all major body segments, we present here the thorax/upper torso as an exemplar of our approach (Table 1). The complete table for all body segments is available at human-sensor-placement.github.io/anatomical_table.html and in the supplementary materials.\nTable 1: Example Implementation for the Thorax/Upper Torso\n\n\n\n\n\n\n\n\n\n\nBody Part\nAnatomical Description\nAnatomical Landmarks\nCoordinate System\nImage\n\n\n\n\nTorso-chest\nThe upper part of the torso, extending from the base of the neck to the diaphragm, framed by the rib cage, which includes the ribs, sternum, and thoracic vertebrae.\nLeft Acromion Process (LAP), Right Acromion Process (RAP), C7 vertebra (C7), Xiphoid Process\nX: LAP → RAP; Y: C7 → Xiphoid Process (shorter axis); Z: C7 → Xiphoid Process (longer axis)\n\n\n\n\nThis example demonstrates the essential aspects of our framework through several key components. The anatomical definition provides a clear description of the body segment and its boundaries using standard anatomical terminology. The selected landmarks consist of easily palpable and minimally mobile anatomical points that form a stable reference frame. The coordinate system definition specifies unambiguous axes using landmark pairs, with clear directional conventions. Practical applications are illustrated through example placement coordinates for common sensing modalities, expressed as percentages along each defined axis.\nThe same systematic approach is applied to all body segments in the complete reference table. Each entry maintains this structure while accounting for segment-specific anatomical considerations and common sensing applications. The complete table includes detailed specifications for 15 major body segments, covering the full body from head to feet. This comprehensive reference enables consistent sensor placement across different applications while maintaining the precision and reproducibility principles outlined in our framework.\n\n\n\nWe present a comprehensive framework standardizing sensor placement in human movement and physiological monitoring applications. Through precise definitions of anatomical landmarks, coordinate systems, and placement protocols, we enable reproducible sensor positioning across different applications and laboratories. Our approach offers a systematic method for documenting and reproducing sensor placements through normalized coordinate systems and clearly defined precision levels.\nOur framework bridges existing standards across different domains. While SENIAM for electromyography and Mason-Likar for electrocardiography serve their specific applications well, modern applications demand integration of multiple sensing modalities. We complement these standards by providing a common language for sensor placement that maps to domain-specific requirements. This standardization enhances data FAIRness (Findability, Accessibility, Interoperability, and Reusability) by enabling clear documentation and facilitating data sharing across research groups and applications.\nWe identify several key developments necessary to enhance the practical implementation of this framework. First, this framework does not provide specific vocabulary or a standardized way to communicate sensor placement. Standard bodies such as BIDS and HED can provide formal specifications, vocabulary cross-references, and specific guidelines based on their norms and guidelines. A validation study involving multiple operators placing sensors according to the guidelines is needed to quantify inter-operator reliability and refine precision specifications. We also plan to develop explicit mappings between our framework and existing standards like SENIAM to facilitate adoption. Furthermore, software tools for coordinate calculation and placement visualization will support practical implementation.\nLimitations of this framework include operator dependency and anatomical variability considerations. While we provide precise definitions and measurement protocols, achieving specified precision levels depends on operator expertise and training. The framework cannot fully address the subjective aspects of anatomical landmark identification, particularly in subjects with varying body compositions. Additionally, our current focus on static placement may require adaptation for dynamic applications where sensor position might change during movement.\nWe believe our standardization framework significantly advances the quality and reproducibility of human movement and physiological data collection. By unifying sensor placement across different applications, this framework addresses a critical need in biomechanics and health science research. Our framework’s flexibility in accommodating different precision requirements while maintaining consistency makes it valuable for applications ranging from clinical research to consumer health monitoring. As wearable technology continues to advance and integrate multiple sensing modalities, this standardization effort will become increasingly important. We provide a foundation for future developments in sensor placement standardization and welcome community feedback to evolve the framework alongside technological advancement.\n\n\n\nAll the information about the framework is available on human-sensor-placement.github.io and the source files are available at the corresponding GitHub repository1.\n\n\n\nJW proposed the framewrok. SYS, JW and SJ formalized the framwwoek structure. SYS formulated the anatomical landmarks. SYS, JW, and SJ drafted the framework and the manuscript. LG created the graphics.\n\n\n\n1. Wong Y-M, Ng GYF. Surface electrode placement affects the EMG recordings of the quadriceps muscles. Phys Ther Sport. 2006;7: 122-127.\n2. Tan T, Chiasson DP, Hu H, Shull PB. Influence of IMU position and orientation placement errors on ground reaction force estimation. J Biomech. 2019;97: 109416.\n3. Osis ST, Hettinga BA, Macdonald S, Ferber R. Effects of simulated marker placement deviations on running kinematics and evaluation of a morphometric-based placement feedback method. PLoS One. 2016;11: e0147111.\n4. Bond RR, Finlay DD, Nugent CD, Breen C, Guldenring D, Daly MJ. The effects of electrode misplacement on clinicians’ interpretation of the standard 12-lead electrocardiogram. Eur J Intern Med. 2012;23: 610-615.\n5. Bond RR, Finlay DD, Nugent CD, Moore G, Guldenring D. A simulation tool for visualizing and studying the effects of electrode misplacement on the 12-lead electrocardiogram. J Electrocardiol. 2011;44: 439-444.\n6. Roy SK, Shah SU, Villa-Lopez E, Murillo M, Arenas N, Oshima K, et al. Comparison of electrocardiogram quality and clinical interpretations using prepositioned ECG electrodes and conventional individual electrodes. J Electrocardiol. 2020;59: 126-133.\n7. Hermens HJ, Freriks B, Merletti R, Stegeman D, Blok J, Rau G, et al. European recommendations for surface electromyography. Roessingh research and development. 1999;8: 13-54.\n8. Mason RE, Likar I. A new system of multiple-lead exercise electrocardiography. Am Heart J. 1966;71: 196-205.\n9. Francis J. ECG monitoring leads and special leads. Indian Pacing Electrophysiol J. 2016;16: 92-95.\n10. Campanini I, Disselhorst-Klug C, Rymer WZ, Merletti R. Surface EMG in clinical assessment and neurorehabilitation: Barriers limiting its use. Front Neurol. 2020;11: 934.\n11. Manca A, Cereatti A, Bar-On L, Botter A, Della Croce U, Knaflitz M, et al. A survey on the use and barriers of surface electromyography in neurorehabilitation. Front Neurol. 2020;11: 573616.\n12. Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, et al. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Sci Data. 2016;3: 160044.\n13. Robbins K, Truong D, Appelhoff S, Delorme A, Makeig S. Capturing the nature of events and event context using hierarchical event descriptors (HED). Neuroimage. 2021;245: 118766.\n14. Hanavan EP Jr. A personalized mathematical model of the human body. J Spacecr Rockets. 1966;3: 446-448."
  },
  {
    "objectID": "paper.html#abstract",
    "href": "paper.html#abstract",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "The proliferation of wearable sensors and monitoring technologies has created an urgent need for standardized sensor placement protocols. While existing standards like SENIAM address specific applications, no comprehensive framework spans different sensing modalities and applications. We present a unified sensor placement standard that ensures the reproducibility and transferability of human movement and physiological data across various systems and research domains. Our framework provides precise anatomical landmarks, coordinate systems, and placement protocols with defined precision levels, compatible with existing data-sharing standards such as the Brain Imaging Data Structure (BIDS) and Heirechciacal Event Descriptors (HED). This framework aims to enhance data quality, reproducibility, and interoperability in applications ranging from lab-based clinical biomechanics to continuous health monitoring in everyday life."
  },
  {
    "objectID": "paper.html#introduction",
    "href": "paper.html#introduction",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "The measurement of human movement and physiological signals is fundamental to fields ranging from biomechanics and clinical rehabilitation to continuous health monitoring and virtual reality. Technological advancements in motion capture systems, inertial sensors, and wearable devices have expanded analysis beyond traditional laboratory settings. Standardization of sensor placement practices is essential to improve data quality, reproducibility, and interoperability across these diverse applications.\nThe impact of sensor placement variation on data quality is well-documented. In biomechanics research, studies have shown that even small changes in sensor position can significantly affect measurement outcomes. In electromyography (EMG), electrode placement variations of just 2-3 cm can lead to signal amplitude changes of up to 50% and altered muscle activation patterns [1]. Similar effects have been observed with inertial measurement units (IMUs), where placement variations can substantially impact acceleration and angular velocity measurements during dynamic movements [2]. The same applies to Optical Motion Capture, where deviations from the predefined marker positions affect gait detection accuracy [3].\nPrecise sensor placement is critical beyond movement analysis. In electrocardiography (ECG), electrode positioning directly affects waveform morphology and diagnostic accuracy, with small deviations potentially leading to misinterpretation of cardiac conditions [4-6]. Continuous glucose monitoring systems require consistent sensor placement to maintain measurement accuracy and reduce variability. Temperature monitoring, particularly for early fever detection or athletic performance, depends heavily on sensor location due to significant variations in skin temperature across different body regions. Emerging technologies like sweat-based biochemical sensors also necessitate standardized placement to account for regional variations in sweat gland density and composition.\nCurrent standards for sensor placement, such as SENIAM for EMG [7] or the Mason-Likar configuration for ECG [8,9], while valuable, are limited and not comprehensive for modern sensing modalities. Moreover, these standards are often not sufficiently implemented in practice [10,11], failing to incorporate a wider user base with varying levels of expertise in anatomy, biomechanics, and biosensors.\nThe emergence of consumer wearables and virtual reality applications has further highlighted the limitations of current standards. These technologies often combine multiple sensing modalities—motion, heart rate, temperature, and other physiological parameters—requiring consistent sensor placement for reliable long-term monitoring and accurate data collection. The growing integration of these technologies demands a unified approach to sensor placement that accommodates different measurement contexts while maintaining precision and reproducibility.\nThe need for a comprehensive sensor placement standard is increasingly pressing with the rise of large-scale data-sharing initiatives and the use of machine-learning techniques in health monitoring and movement analysis. These applications require consistent and well-documented data collection protocols for meaningful comparisons and reliable results. Current data-sharing standards like BIDS [12] and HED [13] provide robust frameworks for data organization but lack specific guidelines for sensor placement across the full range of human monitoring applications.\nWe present a unified sensor placement framework addressing these challenges through a comprehensive system of anatomical landmarks, coordinate systems, and placement protocols. Our standard defines anatomical reference points and coordinate systems for body segments [14], establishes a hierarchical system of reference frames for different measurement contexts, and provides quantifiable levels of placement precision with associated uncertainty estimates. The framework is technology- and specification-agnostic, accommodating various sensing modalities while maintaining compatibility with existing data-sharing standards. This framework will also allow existing records to be annotated with the proposed framework.\nThe following sections detail our proposed standard, beginning with fundamental definitions and proceeding to specific placement protocols for different body segments and sensing modalities. We provide guidance on precision levels and documentation requirements, concluding with recommendations for implementation and validation. This framework represents a significant step toward standardizing sensor placement across the broader field of human biosensing, from traditional biomechanics applications to emerging technologies in continuous health monitoring and virtual reality."
  },
  {
    "objectID": "paper.html#fundamentals-of-the-framework",
    "href": "paper.html#fundamentals-of-the-framework",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "The foundation of our standardization framework rests on precise definitions of anatomical landmarks and spatial references. These definitions ensure consistent interpretation and implementation across different applications and laboratories.\nA reference frame consists of an origin point and a set of axes that define directions in space. In human movement analysis, we encounter multiple reference frames: the global laboratory frame, anatomical frames tied to body segments, and sensor- or system-specific frames. The relationships between these frames must be clearly defined to ensure meaningful data interpretation.\nThe anatomical reference frame for each body segment is defined using palpable landmarks that can be reliably identified (see Anatomical Landmark System). These landmarks are used to define the coordinate system of a body segment to provide reference points for sensor placement. Our framework defines each coordinate system through:\n1. An origin point based on specific anatomical landmarks\n2. Primary axes aligned with functional anatomical directions\n3. Clear definitions of positive directions and measurement conventions\n\n\n\nOur framework defines sensor placement locations using local anatomical coordinate systems. These local systems are part of a larger kinematic chain. This approach aligns with practices in biomechanics and robotics, where transformations between local and global coordinate systems are computed through forward kinematics. Although our standard focuses on precise local definitions, users can derive global coordinates through standard transformation techniques. This separation of local definitions from global transformations ensures both precision in sensor placement and flexibility in data analysis.\n\n\n\nOur framework establishes a comprehensive set of anatomical landmarks chosen for their reliability, accessibility across different body types, relevance to common sensor placement needs, and minimal displacement during movement. Each landmark is defined using standardized anatomical terminology and palpation methods to ensure reproducibility. The complete set of landmarks and their definitions is provided in the anatomical landmark table (link), forming the backbone of our standardization system.\n\n\n\nSensor placement precision is quantified through a three-tier system based on the measurement method used:\nLevel 1: ±10% of reference distance, example: visual inspection or eyeballing\nLevel 2: ±5% of reference distance, example: manual measurement using tape\nLevel 3:±1% of reference distance, example: 3D scanning or motion capture-assisted placement\nThese precision levels must be reported with all sensor placement descriptions to ensure appropriate interpretation of the collected data."
  },
  {
    "objectID": "paper.html#unified-placement-scheme",
    "href": "paper.html#unified-placement-scheme",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "The core of our framework is a unified placement scheme that defines sensor locations relative to anatomical landmarks using standardized coordinate systems. Each sensor location is specified in three steps:\n\nIdentify the relevant body segment and its anatomical coordinate system\n\nDetermine the location using normalized coordinates within that local body segment coordinate system (0-100% along each axis)\n\nDetermine the precision level of the sensor location (choose one precision level, see Precision Specifications above).\n\nThis standardized approach ensures reproducibility across different operators and laboratories, scalability to different body sizes and proportions, and clear documentation in research publications. The scheme provides a foundation for consistent sensor placement while maintaining the flexibility needed for diverse applications in human movement analysis."
  },
  {
    "objectID": "paper.html#anatomical-landmark-implementation",
    "href": "paper.html#anatomical-landmark-implementation",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "The practical implementation of our framework relies on precisely defined anatomical landmarks and their relationships. While the complete system covers all major body segments, we present here the thorax/upper torso as an exemplar of our approach (Table 1). The complete table for all body segments is available at human-sensor-placement.github.io/anatomical_table.html and in the supplementary materials.\nTable 1: Example Implementation for the Thorax/Upper Torso\n\n\n\n\n\n\n\n\n\n\nBody Part\nAnatomical Description\nAnatomical Landmarks\nCoordinate System\nImage\n\n\n\n\nTorso-chest\nThe upper part of the torso, extending from the base of the neck to the diaphragm, framed by the rib cage, which includes the ribs, sternum, and thoracic vertebrae.\nLeft Acromion Process (LAP), Right Acromion Process (RAP), C7 vertebra (C7), Xiphoid Process\nX: LAP → RAP; Y: C7 → Xiphoid Process (shorter axis); Z: C7 → Xiphoid Process (longer axis)\n\n\n\n\nThis example demonstrates the essential aspects of our framework through several key components. The anatomical definition provides a clear description of the body segment and its boundaries using standard anatomical terminology. The selected landmarks consist of easily palpable and minimally mobile anatomical points that form a stable reference frame. The coordinate system definition specifies unambiguous axes using landmark pairs, with clear directional conventions. Practical applications are illustrated through example placement coordinates for common sensing modalities, expressed as percentages along each defined axis.\nThe same systematic approach is applied to all body segments in the complete reference table. Each entry maintains this structure while accounting for segment-specific anatomical considerations and common sensing applications. The complete table includes detailed specifications for 15 major body segments, covering the full body from head to feet. This comprehensive reference enables consistent sensor placement across different applications while maintaining the precision and reproducibility principles outlined in our framework."
  },
  {
    "objectID": "paper.html#discussion",
    "href": "paper.html#discussion",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "We present a comprehensive framework standardizing sensor placement in human movement and physiological monitoring applications. Through precise definitions of anatomical landmarks, coordinate systems, and placement protocols, we enable reproducible sensor positioning across different applications and laboratories. Our approach offers a systematic method for documenting and reproducing sensor placements through normalized coordinate systems and clearly defined precision levels.\nOur framework bridges existing standards across different domains. While SENIAM for electromyography and Mason-Likar for electrocardiography serve their specific applications well, modern applications demand integration of multiple sensing modalities. We complement these standards by providing a common language for sensor placement that maps to domain-specific requirements. This standardization enhances data FAIRness (Findability, Accessibility, Interoperability, and Reusability) by enabling clear documentation and facilitating data sharing across research groups and applications.\nWe identify several key developments necessary to enhance the practical implementation of this framework. First, this framework does not provide specific vocabulary or a standardized way to communicate sensor placement. Standard bodies such as BIDS and HED can provide formal specifications, vocabulary cross-references, and specific guidelines based on their norms and guidelines. A validation study involving multiple operators placing sensors according to the guidelines is needed to quantify inter-operator reliability and refine precision specifications. We also plan to develop explicit mappings between our framework and existing standards like SENIAM to facilitate adoption. Furthermore, software tools for coordinate calculation and placement visualization will support practical implementation.\nLimitations of this framework include operator dependency and anatomical variability considerations. While we provide precise definitions and measurement protocols, achieving specified precision levels depends on operator expertise and training. The framework cannot fully address the subjective aspects of anatomical landmark identification, particularly in subjects with varying body compositions. Additionally, our current focus on static placement may require adaptation for dynamic applications where sensor position might change during movement.\nWe believe our standardization framework significantly advances the quality and reproducibility of human movement and physiological data collection. By unifying sensor placement across different applications, this framework addresses a critical need in biomechanics and health science research. Our framework’s flexibility in accommodating different precision requirements while maintaining consistency makes it valuable for applications ranging from clinical research to consumer health monitoring. As wearable technology continues to advance and integrate multiple sensing modalities, this standardization effort will become increasingly important. We provide a foundation for future developments in sensor placement standardization and welcome community feedback to evolve the framework alongside technological advancement."
  },
  {
    "objectID": "paper.html#code-availability",
    "href": "paper.html#code-availability",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "All the information about the framework is available on human-sensor-placement.github.io and the source files are available at the corresponding GitHub repository1."
  },
  {
    "objectID": "paper.html#author-contributions",
    "href": "paper.html#author-contributions",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "JW proposed the framewrok. SYS, JW and SJ formalized the framwwoek structure. SYS formulated the anatomical landmarks. SYS, JW, and SJ drafted the framework and the manuscript. LG created the graphics."
  },
  {
    "objectID": "paper.html#references",
    "href": "paper.html#references",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "",
    "text": "1. Wong Y-M, Ng GYF. Surface electrode placement affects the EMG recordings of the quadriceps muscles. Phys Ther Sport. 2006;7: 122-127.\n2. Tan T, Chiasson DP, Hu H, Shull PB. Influence of IMU position and orientation placement errors on ground reaction force estimation. J Biomech. 2019;97: 109416.\n3. Osis ST, Hettinga BA, Macdonald S, Ferber R. Effects of simulated marker placement deviations on running kinematics and evaluation of a morphometric-based placement feedback method. PLoS One. 2016;11: e0147111.\n4. Bond RR, Finlay DD, Nugent CD, Breen C, Guldenring D, Daly MJ. The effects of electrode misplacement on clinicians’ interpretation of the standard 12-lead electrocardiogram. Eur J Intern Med. 2012;23: 610-615.\n5. Bond RR, Finlay DD, Nugent CD, Moore G, Guldenring D. A simulation tool for visualizing and studying the effects of electrode misplacement on the 12-lead electrocardiogram. J Electrocardiol. 2011;44: 439-444.\n6. Roy SK, Shah SU, Villa-Lopez E, Murillo M, Arenas N, Oshima K, et al. Comparison of electrocardiogram quality and clinical interpretations using prepositioned ECG electrodes and conventional individual electrodes. J Electrocardiol. 2020;59: 126-133.\n7. Hermens HJ, Freriks B, Merletti R, Stegeman D, Blok J, Rau G, et al. European recommendations for surface electromyography. Roessingh research and development. 1999;8: 13-54.\n8. Mason RE, Likar I. A new system of multiple-lead exercise electrocardiography. Am Heart J. 1966;71: 196-205.\n9. Francis J. ECG monitoring leads and special leads. Indian Pacing Electrophysiol J. 2016;16: 92-95.\n10. Campanini I, Disselhorst-Klug C, Rymer WZ, Merletti R. Surface EMG in clinical assessment and neurorehabilitation: Barriers limiting its use. Front Neurol. 2020;11: 934.\n11. Manca A, Cereatti A, Bar-On L, Botter A, Della Croce U, Knaflitz M, et al. A survey on the use and barriers of surface electromyography in neurorehabilitation. Front Neurol. 2020;11: 573616.\n12. Gorgolewski KJ, Auer T, Calhoun VD, Craddock RC, Das S, Duff EP, et al. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Sci Data. 2016;3: 160044.\n13. Robbins K, Truong D, Appelhoff S, Delorme A, Makeig S. Capturing the nature of events and event context using hierarchical event descriptors (HED). Neuroimage. 2021;245: 118766.\n14. Hanavan EP Jr. A personalized mathematical model of the human body. J Spacecr Rockets. 1966;3: 446-448."
  },
  {
    "objectID": "paper.html#footnotes",
    "href": "paper.html#footnotes",
    "title": "A Standardized Framework for Sensor Placement in Human Motion Capture and Wearable Applications",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://github.com/human-sensor-placement/human-sensor-placement.github.io/tree/v0.1.0-alpha↩︎"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024 the Authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "anatomical_table.html",
    "href": "anatomical_table.html",
    "title": "Human Body Segmentation",
    "section": "",
    "text": "Human Body Segmentation\n\n\n\nModified Hanavan model, see Hatze 1980\n\n\n\n\n\nFrom Warmerdam et. al. 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHanavan Body Part\nHED Label\nHED Description\nAnatomical Description\nFiducials\nCoordinate System\nExample IMU\nExample Mocap\nLandmark visualization\n\n\n\n\n\n1\nHead\nThe upper part of the human body, or the front or upper part of the body of an animal, typically separated from the rest of the body by a neck, and containing the brain, mouth, and sense organs.\nThe structure superior to the neck, encasing the brain, eyes, ears, nose, and mouth. It is demarcated by the skull, which separates the head from the neck at the base of the skull.\nNasionInionLeft Helix-Tragus Junction (LHJ)Right Helix-Tragus Junction(RHJ)VertexMidpoint between Mastoid processs(MMP)\nX: LHJ → RHJY: Inion → NasionZ: MMP → Vertex\n1. (50, 0, 50)\n1. (100, 100, 80)2. (0, 100, 80)3. (100, 10, 80)4. (0, 10, 80)\n\n\n\n\nn/a\nNeck\nThe part of the body connecting the head to the torso, containing the cervical spine and vital pathways of nerves, blood vessels, and the airway.\nThe anatomical region bounded by the base of the skull, and the clavicles inferiorly, containing vital structures such as the cervical vertebrae, spinal cord, carotid arteries, and trachea.\nC7 vertebra (C7) Suprasternal Notch (Jugular Notch) Left Mastoid process(LMP)Right Mastoid process (RMP)Midpoint between Mastoid processs(MMP)\nX: LMP → RMPY: C7 → Jugular NotchZ: C7 → MMP\nn/a\nn/a\n\n\n\n\n2\nTorso-chest\nThe body excluding the head and neck and limbs.\nThe upper part of the torso, extending from the base of the neck to the diaphragm. It’s framed by the rib cage, which includes the ribs, sternum, and thoracic vertebrae. The thorax houses vital organs such as the heart and lungs.\nLeft Acromion Process (LAP)Right Acromion Process(RAP)C7 vertebra (C7)Xiphoid Process\nX: LAP → RAPY: C7 → Xiphoid Process (shorter axis)Z: C7 → Xiphoid Process (longer axis)\n2. (50, 100, 70)\n5. (50, 100, 70)A.(100, 100, 30) B.(0, 100, 30)\n\n\n\n\n3\nAbdomen\nThe body excluding the head and neck and limbs.\nThe lower part of the torso, situated between the thorax and the pelvis. It is bounded superiorly by the diaphragm and inferiorly by the pelvic girdle. The abdomen contains important digestive, urinary, and reproductive organs, and is supported by various abdominal muscles.\nUmbilicus (Navel)Left Anterior Superior Iliac Spine (Left ASIS)Right Anterior Superior Iliac Spine (Right ASIS) Posterior Superior Iliac Spine (PSIS) Xiphoid Process\nX: Left ASIS → Right ASISY: midpoint ASIS → midpoint PSISZ: Navel → Xiphoid Process\nn/a\nn/a\n\n\n\n\n4\n(Right, Hand)\nThe distal portion of the upper extremity. It consists of the carpus, metacarpus, and digits.\nThe terminal part of the forearm, beginning at the wrist joint (where the radius and ulna meet the carpal bones) and extending to the fingertips, including the carpus, metacarpus, and phalanges.\nRadial Styloid Process (RSP) Ulnar Styloid Process (USP) Third Metacarpophalangeal Joint (MCP): The knuckle of the middle finger\nX: RSP → USPY: Dorsal → Palmar surface at the midpoint RSP-USPZ: MCP → midpoint RSP-USP\nn/a\n10. (100, 50, 50)\n\n\n\n\n5\n(Left, Hand)\nThe distal portion of the upper extremity. It consists of the carpus, metacarpus, and digits.\nThe terminal part of the forearm, beginning at the wrist joint (where the radius and ulna meet the carpal bones) and extending to the fingertips, including the carpus, metacarpus, and phalanges.\nRadial Styloid Process (RSP) Ulnar Styloid Process (USP) Third Metacarpophalangeal Joint (MCP): The knuckle of the middle finger\nX: USP → RSPY: Dorsal → Palmar surface at the midpoint RSP-USPZ: MCP → midpoint RSP-USP\nn/a\n11. (0, 50, 50)\n\n\n\n\n6\n(Right, Upper-arm)\nPortion of arm between shoulder and elbow.\nThe segment between the shoulder and elbow, outlined by the humerus bone. It starts at the glenohumeral joint and ends at the elbow joint where the humerus meets the radius and ulna.\nAcromion Medial Humerus Epicondyle (MHE) Lateral Humerus Epicondyle (LHE)Posterior Elbow (Olecranon Process) Cubital Fossa\nX: MHE → LHEY: Olecranon Process → Cubital FossaZ: midpoint MHE-LHE → Acromion\n3. (100, 50, 70)\n6. (100, 50, 70)  C. (100, 50, 0)\n\n\n\n\n7\n(Left, Upper-arm)\nPortion of arm between shoulder and elbow.\nThe segment between the shoulder and elbow, outlined by the humerus bone. It starts at the glenohumeral joint and ends at the elbow joint where the humerus meets the radius and ulna.\nAcromion Medial Humerus Epicondyle (MHE) Lateral Humerus Epicondyle (LHE)Posterior Elbow (Olecranon Process) Cubital Fossa\nX: MHE → LHEY: Olecranon Process → Cubital FossaZ: midpoint MHE-LHE → Acromion\n4. (0, 50, 70)\n7. (0, 50, 50)  D. (0, 50, 0)\n\n\n\n\n8\n(Right, Forearm)\nLower part of the arm between the elbow and wrist.\nExtends from the elbow to the wrist, demarcated by the radius and ulna. Begins at the elbow joint and ends at the wrist joint.\nRadial Styloid Process (RSP) Ulnar Styloid Process (USP) Lateral Humerus Epicondyle (LHE) Posterior Elbow (Olecranon Process) Cubital Fossa\nX: RSP → USPY: Right-hand rule (limits: Olecranon Process → Cubital Fossa)Z: midpoint RSP-USP → LHE\n5. (100, 50, 30)\n8. (100, 50, 70)  E. (50, 100, 0)\n\n\n\n\n9\n(Left, Forearm)\nLower part of the arm between the elbow and wrist.\nExtends from the elbow to the wrist, demarcated by the radius and ulna. Begins at the elbow joint and ends at the wrist joint.\nRadial Styloid Process (RSP) Ulnar Styloid Process (USP) Lateral Humerus Epicondyle (LHE) Posterior Elbow (Olecranon Process) Cubital Fossa\nX: USP → RSPY: Right-hand rule (limits: Olecranon Process → Cubital Fossa)Z: midpoint RSP-USP → LHE\n6. (0, 50, 30)\n9. (0, 50, 50)  E. (50, 100, 0)\n\n\n\n\n10\n(Right, Thigh)\nUpper part of the leg between hip and knee.\nThe part of the lower limb extending from the hip to the knee, primarily composed of the femur. It starts at the hip joint (where the femur connects with the pelvic girdle) and ends at the knee joint.\nGreater Trochanter Femur Medial Epicondyle (FME) Femur Lateral Epicondyle (FLE) Patellar Anterior Surface  Back of the knee (Popliteal Fossa)\nX: FME → FLEY: Popliteal Fossa → Patellar Anterior SurfaceZ: midpoint FME-FLE → Greater Trochanter\n7. (100, 50, 50)\n12. (100, 50, 50)\n\n\n\n\n11\n(Left, Thigh)\nUpper part of the leg between hip and knee.\nThe part of the lower limb extending from the hip to the knee, primarily composed of the femur. It starts at the hip joint (where the femur connects with the pelvic girdle) and ends at the knee joint.\nGreater Trochanter Femur Medial Epicondyle (FME) Femur Lateral Epicondyle (FLE) Patellar Anterior Surface  Back of the knee (Popliteal Fossa)\nX: FLE → FMEY: Popliteal Fossa → Patellar Anterior SurfaceZ: midpoint FME-FLE → Greater Trochanter\n8. (0, 50, 50)\n13. (0, 50, 50)\n\n\n\n\n12\n(Right, Lower-leg)\nThe part of the leg between the knee and the ankle.\nCalf: The posterior segment of the lower leg, from the knee to the ankle. The calf muscles (gastrocnemius and soleus) overlay the tibia and fibula, starting below the knee joint and extending to the ankle. Shin: The anterior part of the lower leg, starting just below the knee joint and extending to the ankle. It primarily involves the tibia.\nLateral Malleolus (LM) Medial Malleolus (MM) Patellar Anterior Surface  Back of the knee (Popliteal Fossa)\nX: MM → LMY: Popliteal Fossa → Patellar Anterior SurfaceZ: midpoint MM-LM → Patellar Anterior Surface\n9. (0, 50, 80)  11. (100, 50, 20)\n14. (100, 50, 80) G. (100, 50, 0)\n\n\n\n\n13\n(Left, Lower-leg)\nThe part of the leg between the knee and the ankle.\nCalf: The posterior segment of the lower leg, from the knee to the ankle. The calf muscles (gastrocnemius and soleus) overlay the tibia and fibula, starting below the knee joint and extending to the ankle. Shin: The anterior part of the lower leg, starting just below the knee joint and extending to the ankle. It primarily involves the tibia.\nLateral Malleolus (LM) Medial Malleolus (MM) Patellar Anterior Surface  Back of the knee (Popliteal Fossa)\nX: LM → MMY: Popliteal Fossa → Patellar Anterior SurfaceZ: midpoint MM-LM → Patellar Anterior Surface\n10. (100, 50, 80)  12. (0, 50, 20)\n15. (0, 50, 80) G. (0, 50, 0)\n\n\n\n\n14\n(Right, Foot)\nThe structure found below the ankle joint required for locomotion.\nThe distal extremity of the lower leg, starting at the ankle joint (where the tibia, fibula, and talus meet) and extending to the tips of the toes. It includes the tarsus, metatarsus, and phalanges.\nHeel Bone, Calcaneal Tuberosity (CT) Tip of the big toe, First Metatarsal Head (FME) Lateral Malleolus (LM) Medial Malleolus (MM)\nX: MM → LMY: CT → FMEZ: CT to MM-LM line\n13. (50, 60, 80)\n16. (50, 100, 40)18. (50, 0, 50)\n\n\n\n\n15\n(Left, Foot)\nThe structure found below the ankle joint required for locomotion.\nThe distal extremity of the lower leg, starting at the ankle joint (where the tibia, fibula, and talus meet) and extending to the tips of the toes. It includes the tarsus, metatarsus, and phalanges.\nHeel Bone, Calcaneal Tuberosity (CT) Tip of the big toe, First Metatarsal Head (FME) Lateral Malleolus (LM) Medial Malleolus (MM)\nX: LM → MMY: CT → FMEZ: CT to MM-LM line\n14. (50, 60, 80)\n17. (50, 100, 40)19. (50, 0, 50)\n\n\n\n\n\nNOTE: Joint markers should be annotated in the same coordinate system as their proximal body part. For example, the right shoulder joint marker should be annotated in the same coordinate system as torso, and the right elbow joint marker should be annotated in the same coordinate system as the right upper-arm."
  }
]